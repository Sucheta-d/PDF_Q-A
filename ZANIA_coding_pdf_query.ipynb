{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f77fc5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q cassio datasets langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51d2f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-community in /home/sucheta/.local/lib/python3.8/site-packages (0.2.11)\n",
      "Requirement already satisfied: langchain-core in /home/sucheta/.local/lib/python3.8/site-packages (0.2.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-community) (3.10.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-community) (0.1.98)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-community) (5.3.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-community) (0.5.7)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-community) (1.23.5)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-community) (0.2.12)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-community) (8.1.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-community) (1.4.35)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-core) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sucheta/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/sucheta/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/sucheta/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/sucheta/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/sucheta/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sucheta/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/sucheta/.local/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/sucheta/.local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.15.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/sucheta/.local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/sucheta/.local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.7.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/sucheta/.local/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/sucheta/.local/lib/python3.8/site-packages (from langchain<0.3.0,>=0.2.12->langchain-community) (0.2.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/sucheta/.local/lib/python3.8/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/sucheta/.local/lib/python3.8/site-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/sucheta/.local/lib/python3.8/site-packages (from pydantic<3,>=1->langchain-core) (2.20.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sucheta/.local/lib/python3.8/site-packages (from requests<3,>=2->langchain-community) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (2.8)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/sucheta/.local/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/sucheta/.local/lib/python3.8/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (0.4.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain-community langchain-core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb7c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary langchain components\n",
    "\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "#cassio will be used to integrate database in the langchain\n",
    "import cassio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36cba7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in /home/sucheta/.local/lib/python3.8/site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /home/sucheta/.local/lib/python3.8/site-packages (from PyPDF2) (4.12.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install PyPDF2             #it is required to read the pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd7ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff5a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary database token, id and openai_api key\n",
    "\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN= # put the database token\n",
    "ASTRA_DB_ID= # put the database id\n",
    "OPENAI_API_KEY= #put openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1864d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is the pdf from where the question will be asked \n",
    "\n",
    "pdfreader=PdfReader(\"/home/sucheta/Downloads/GraMMY.pdf\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a296f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_text contains the full text from the input pdf\n",
    "\n",
    "\n",
    "from typing_extensions import Concatenate\n",
    "raw_text=\"\"\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content=page.extract_text()\n",
    "    if content:\n",
    "        raw_text+=content       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f399ac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraMMy: Graph Representation Learning based on\n",
      "Micro-Macro Analysis\n",
      "Sucheta Dawn, Monidipa Das, Sang\n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:100])           #it will print first 100 character from the pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48388f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization of connection between database and langchain \n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9846e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sucheta/.local/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/sucheta/.local/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#llm object and langchain embedding\n",
    "\n",
    "llm=OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "embedding=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df74c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain vector store will be created in the database in the table named as \"QA_from_GraMMy\"\n",
    "astra_vector_store=Cassandra(\n",
    "embedding=embedding,\n",
    "table_name=\"QA_from_GRaMMy\",\n",
    "session=None,\n",
    "keyspace=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dede510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the whole text will be splitted into text chunk of chunk size 800\n",
    "\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter=CharacterTextSplitter(\n",
    "separator=\"\\n\",\n",
    "chunk_size=800,\n",
    "chunk_overlap=200,\n",
    "length_function=len,\n",
    ")\n",
    "texts=text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "525515ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GraMMy: Graph Representation Learning based on\\nMicro-Macro Analysis\\nSucheta Dawn, Monidipa Das, Sanghamitra Bandyopadhyay\\nMachine Intelligence Unit, Indian Statistical Institute, Kolkata, India\\nAbstract\\nGraph Neural Networks (GNNs) are robust variants of deep network models, typ-\\nically designed to learn from graph-structured data. Despite the recent advance-\\nment of GNNs, the basic message passing scheme of learning often holds back\\nthese models in effectively capturing the inﬂuence of the nodes from higher order\\nneighbourhood. Further, the state-of-the-art approaches mostly ignore the contex-\\ntual signiﬁcance of the paths through which the message/information propagates\\nto a node. In order to deal with these two issues, we propose GraMMY as a novel',\n",
       " 'tual signiﬁcance of the paths through which the message/information propagates\\nto a node. In order to deal with these two issues, we propose GraMMY as a novel\\nframework for hierarchical semantics-driven gra ph representation learning based\\non M icro-M acro analy sis. The key idea here is to study the graph structure from\\ndifferent levels of abstraction, which not only provides an opportunity for ﬂexible\\nﬂow of information from both local and higher-order neighbours but also helps\\nin more concretely capturing how information travels within various hierarchical\\nstructures of the graph. We incorporate the knowledge gained from micro and\\nmacro level semantics into the embedding of a node and use this to perform graph',\n",
       " 'structures of the graph. We incorporate the knowledge gained from micro and\\nmacro level semantics into the embedding of a node and use this to perform graph\\nclassiﬁcation. Experimentations on four bio-informatics and two social datasets\\nexhibit the superiority of GraMMy over state-of-the-art GNN-based graph classi-\\nﬁers.\\nKeywords: Graph Neural Network, Micro-Macro analysis, Locality Sensitive\\nHashing, Context-based learning\\nEmail addresses: suchetad_r@isical.ac.in (Sucheta Dawn),\\nmonidipa_t@isical.ac.in (Monidipa Das), sanghami@isical.ac.in\\n(Sanghamitra Bandyopadhyay)\\nPreprint submitted to Neurocomputing May 21, 20211. Introduction\\nGraph is a pervasive structure, which is used to represent complex systems',\n",
       " '(Sanghamitra Bandyopadhyay)\\nPreprint submitted to Neurocomputing May 21, 20211. Introduction\\nGraph is a pervasive structure, which is used to represent complex systems\\nwhere both entities and their interconnections are equally important for realization[5].\\nReal-life situations, e.g., social network, biological network, recommender sys-\\ntem, etc., are better to be modeled in terms of graphical structure, as the infor-\\nmation about individual entities is not enough to understand the whole system\\n[26, 29]. The rich information about their communal activities is also needed to\\nbe captured. Thus, acquiring the euclidean representation of the nodes and the\\ngraphs for solving machine learning tasks on the graph has become a fascinating',\n",
       " 'be captured. Thus, acquiring the euclidean representation of the nodes and the\\ngraphs for solving machine learning tasks on the graph has become a fascinating\\narea of research in recent years. Graph Neural Network (GNN) uses deep learning\\ntechniques to serve the purpose and has been proved to be extremely beneﬁcial in\\nmany applications such as recognition, classiﬁcation, clustering, prediction, and\\nso on [20, 15, 6].\\nRelated works and limitations: In GNN literature, most of the approaches fol-\\nlow more or less similar kind of method called ”Message Passing” scheme, where\\na GNN layer iteratively ﬁnds euclidean representation of a node by aggregating\\nneighbours’ feature and combining with existing node embedding (randomly ini-',\n",
       " 'a GNN layer iteratively ﬁnds euclidean representation of a node by aggregating\\nneighbours’ feature and combining with existing node embedding (randomly ini-\\ntialized). Hence, the choice of two functions, namely Aggregate andCombine\\nturns out to be crucial for this approach. We discuss some of the existing mod-\\nels from the GNN literature here. The GNN approach proposed by Scarselli et\\nal. [19], is one of the earliest works in this domain. The approach recursively\\nupdates node latent representations by exchanging information with the neigh-\\nbouring nodes until equilibrium is reached. The recurrent function is chosen to be\\na contraction mapping to ensure convergence. The Gated Graph Neural Network\\n(GGNN)[2] uses a gated recurrent unit as the recurrent function and uses back-',\n",
       " 'a contraction mapping to ensure convergence. The Gated Graph Neural Network\\n(GGNN)[2] uses a gated recurrent unit as the recurrent function and uses back-\\npropagation through time (BPTT) for parameter learning. The approach does not\\nrequire any condition on parameters to converge and thus reduces the number of\\nsteps. However, these models of GNN learning often ﬁnd it difﬁcult to work on\\nlarger graphs and may often suffer from the stability issue. Recently introduced\\nStochastic Steady-State Embedding (SSE) approach [3] uses a recurrent function\\nwhich takes aweighted average of the states from previous steps and a new state\\nto ensure the stability of the algorithm. The GraphSage model [7] overcomes\\nthe scalability issue by proposing a batch-training algorithm that samples a ﬁxed-',\n",
       " 'to ensure the stability of the algorithm. The GraphSage model [7] overcomes\\nthe scalability issue by proposing a batch-training algorithm that samples a ﬁxed-\\nsized neighbourhood of a node to aggregate information.Among the various GNN\\nmodels, the Graph Isomorphism Network (GIN) [27] is found to have the maxi-\\nmum representational power. GIN achieves this by imposing a constraint on the\\n2functions used in the model. As claimed in [27], both GIN and WL test are equally\\npowerful in a graph classiﬁcation task.\\nHowever, the aggregation and combination strategies as used by these models\\nhelp GNN layer to primarily accommodate only local information from the sur-\\nrounding of each node. To encode the feature of the higher-order neighbourhood',\n",
       " 'help GNN layer to primarily accommodate only local information from the sur-\\nrounding of each node. To encode the feature of the higher-order neighbourhood\\nof a node in its node embedding, two strategies can be applied [32]. The ﬁrst one\\nis to increase the iterations so that GNN learning process spreads all nodes’ in-\\nformation over the entire graph. The second strategy can be stacking more GNN\\nlayers. However, both strategies have some practical drawbacks. Increasing iter-\\nations will need a large number of training examples to train the model [31] and\\nincreasing the GNN layer will lead to vanishing gradient problem during train-\\ning [13]. Though the generalized k-dimensional GNNs ( k-GNNs) [16] take into\\naccount the higher-order structures by employing k-dimensional WL algorithm',\n",
       " 'ing [13]. Though the generalized k-dimensional GNNs ( k-GNNs) [16] take into\\naccount the higher-order structures by employing k-dimensional WL algorithm\\n(k-WL), these only look into the overall feature information received from these\\nneighbours. Consequently, similar to the other GNN models, the k-GNNs also\\nignore several interesting facts, such as through which path the information ﬂows\\nfrom a speciﬁc neighbour, that may be crucial for generating better embedding of\\nthe target node [18].\\nIn this paper, we demonstrate that hierarchically analyzing the semantics be-\\nhind graph structure can help GNN in better capturing the information ﬂow from\\nboth local and higher order neighbours, while eliminating the need of increasing\\ntraining samples and/or increasing layer in GNN model.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showsfirst 10 text chunks\n",
    "\n",
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8ea438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_vector_store.add_texts(texts)\n",
    "astra_vector_index=VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd42ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionreader=PdfReader(\"/home/sucheta/Downloads/Question.pdf\")\n",
    "raw_question=\"\"\n",
    "for i, page in enumerate(questionreader.pages):\n",
    "    content=page.extract_text()\n",
    "    if content:\n",
    "        raw_question+=content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36f732df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e735884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is Micro-macro scalar?', 'What is the first paper in the Reference?', 'Who are the authors of GraMMy?']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "questions=raw_question.split(\"\\n\")\n",
    "print(questions)\n",
    "print(len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "700e0edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is Micro-macro scalar?\n",
      "0.913121013542352\n",
      "AnswerMicro-macro scalar is a function that takes a graph G and an amount of detail f as inputs and outputs another graph G0f and an epimorphismf such that it decides the correspondence between Gand the new graph G0 based on the level of abstraction f.\n",
      "What is the first paper in the Reference?\n",
      "0.8716846530357313\n",
      "AnswerThe first paper in the reference is \"Protein function prediction via graph kernels\" by Karsten M Borgwardt, Cheng Soon Ong, Stefan Schonauer, SVN Vishwanathan, Alex J Smola, and Hans-Peter Kriegel.\n",
      "Who are the authors of GraMMy?\n",
      "0.9073243432001957\n",
      "AnswerI don't know.\n"
     ]
    }
   ],
   "source": [
    "with open('Answer.txt','w') as g:\n",
    "    for question in questions:\n",
    "        g.write(\"Question: \"+str(question)+\"\\n\")\n",
    "        print(question)\n",
    "        answer=astra_vector_index.query(question,llm=llm).strip()\n",
    "        for doc, score in astra_vector_store.similarity_search_with_score(question,k=1):\n",
    "            print(score)\n",
    "            if(score<0.80):\n",
    "                print(\"Data not available\")\n",
    "                g.write(\"Answer: \"+\"Data not available\"+\"\\n\")\n",
    "            else:\n",
    "                print(\"Answer%s\"%answer)\n",
    "                g.write(\"Answer: \"+str(answer)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6eca22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350d167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8407e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b33c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676bdad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a7a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a549c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668cb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4b745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afd2e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4210c009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a949c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b47e1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36c8b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36a118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1598ec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11422720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431da35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7284d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
